{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MC3_ImageWrangling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kytk/MagiciansCorner/blob/master/MC3_ImageWrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZK4SI9igWMa"
      },
      "source": [
        "# Cell #1\n",
        "# Copyright (C) Bradley J Erickson and RSNA, 2019\n",
        "# The first cell (run Cell #1) loads in a few data sets of interest, including: T1, T2, GAD on several subjects with brain tumors. \n",
        "# these are DICOM images, so we have to first convert them to nifti\n",
        "# and the nifti converter leaves the output in the source folder, so we have\n",
        "# to move them and also rename them. Will use python for that\n",
        "\n",
        "# The accompanying article can be found at:\n",
        "# https://pubs.rsna.org/doi/full/10.1148/ryai.2019190126\n",
        "\n",
        "!rm -rf MC-ImageWrangling\n",
        "\n",
        "\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=12yk9kJzY-8T68cvkes_YtKsBfjwk4WYk' -O ./Bet-n-dcm2nii.zip\n",
        "!unzip -q ./Bet-n-dcm2nii.zip\n",
        "!rm -rf images\n",
        "\n",
        "!mkdir images\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=19SuwH3NbFweutkFpa3W7tieF351yvDRM' -O ./S1-4.zip\n",
        "!cd images; unzip -q \"../S1-4.zip\" \n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1kE8dqVUBwUuyh3ZSj5h2cPZqJMj0G6P2' -O ./S5-8.zip\n",
        "!cd images; unzip -q \"../S5-8.zip\" \n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1f5ncqzCVNugrRppzxqKuwqz1WxETszUP' -O ./S9-12.zip\n",
        "!cd images; unzip -q \"../S9-12.zip\" \n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1raVoqd6Egfy3C0Hw4m-gL0Aw3wNEzcKd' -O ./S13-16.zip\n",
        "!cd images; unzip -q \"../S13-16.zip\" \n",
        "\n",
        "!rm -rf nii\n",
        "!rm -rf tmp\n",
        "\n",
        "!mkdir tmp\n",
        "!mkdir nii\n",
        "\n",
        "NIFTI_PATH = './nii'\n",
        "# now some python code to loop over all the folders and convert from DICOM to nifti\n",
        "# and then since the command doesn't allow speciyfing the name, will also move\n",
        "#them from temp directory to an organized directory.\n",
        "# this is why seemingly simple tasks always take longer than planned...\n",
        "\n",
        "import os, fnmatch\n",
        "\n",
        "for subj in fnmatch.filter(os.listdir('./images'), 'S*'):\n",
        "    subj_path = os.path.join('./images', subj)\n",
        "    series = os.listdir(subj_path)\n",
        "    series = ['T1', 'T2', 'GAD']\n",
        "    for ser in series:\n",
        "        dcm_path = os.path.join (subj_path, ser)\n",
        "        cmd = \"./dcm2nii -o tmp %s\" % (dcm_path)\n",
        "        os.system(cmd)\n",
        "#        print (cmd)\n",
        "        # now have to find tehe .nii.gz and move it out\n",
        "        f = fnmatch.filter(os.listdir('./tmp'), '*.nii.gz')\n",
        "        out_dir = os.path.join (NIFTI_PATH, subj)\n",
        "        if not os.path.exists(out_dir):\n",
        "            os.mkdir(out_dir)\n",
        "        out_path = os.path.join (out_dir, ser)\n",
        "        cmd = \"mv ./tmp/%s %s.nii.gz\" % (f[0], out_path)\n",
        "        os.system(cmd)\n",
        "#        print (cmd)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWSW7VUOhpK9"
      },
      "source": [
        "# CELL #2\n",
        "# Now do some basic processing to prepare the images\n",
        "# Note this will take about 30 minutes to complete.\n",
        "# If you want to skip it, the output is already computed and saved for next cell\n",
        "\n",
        "\n",
        "# FSL (flirt-the image registration application) complains if this environment variable is not set\n",
        "os.environ['FSLOUTPUTTYPE'] = 'NIFTI_GZ'\n",
        "\n",
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), '*.nii.gz')\n",
        "    for ser in ['T1', 'T2', 'GAD']:\n",
        "        nii_file = os.path.join (subj_path, ser)\n",
        "# First, perform N4 bias correction. Not required, but may improve results. Also must track new names\n",
        "        new_file = os.path.join (subj_path, 'N4-' + ser)\n",
        "        cmd = \"./N4BiasFieldCorrection -i %s.nii.gz -o %s.nii.gz\" % (nii_file, new_file)\n",
        "        os.system(cmd)\n",
        "#        print (cmd)\n",
        "# Next, Register the images to the post-Gad images so skip the GAD\n",
        "    GAD_file = os.path.join (subj_path, 'N4-GAD.nii.gz')\n",
        "    T1_file =  os.path.join (subj_path, 'N4-T1.nii.gz')\n",
        "    new_file = os.path.join (subj_path, 'Reg-T1.nii.gz')\n",
        "    cmd = \"./flirt -in %s -ref %s  -out %s\" % (T1_file, GAD_file, new_file)\n",
        "    os.system(cmd)\n",
        "#    print (cmd)\n",
        "    T2_file =  os.path.join (subj_path, 'N4-T2.nii.gz')\n",
        "    new_file = os.path.join (subj_path, 'Reg-T2.nii.gz')\n",
        "    cmd = \"./flirt -in %s -ref %s  -out %s\" % (T2_file, GAD_file, new_file)\n",
        "    os.system(cmd)\n",
        "#    print (cmd)\n",
        "# can also try to mask out non-brain tissue, but that doesn't work as well on thick slice MRI\n",
        "# first, compute the mask. \n",
        "#    cmd = \"./bet2 %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'Reg-T1'), os.path.join (subj_path, 'mask'))\n",
        "#    os.system(cmd)\n",
        "#    cmd = \"./fslmaths %s.nii.gz -mas %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'Reg-T1'), os.path.join (subj_path, 'mask'), os.path.join (subj_path, 'Reg-T1'))\n",
        "#    os.system(cmd)\n",
        "#    cmd = \"./fslmaths %s.nii.gz -mas %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'Reg-T2'), os.path.join (subj_path, 'mask'), os.path.join (subj_path, 'Reg-T2'))\n",
        "#    os.system(cmd)\n",
        "#    cmd = \"./fslmaths %s.nii.gz -mas %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'N4-GAD'), os.path.join (subj_path, 'mask'), os.path.join (subj_path, 'N4-GAD'))\n",
        "\n",
        "# finally, copy over original so you can skip these steps if you like\n",
        "    cmd = \"cp %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'Reg-T1'), os.path.join (subj_path, 'T1'))\n",
        "    os.system(cmd)\n",
        "    cmd = \"cp %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'Reg-T2'), os.path.join (subj_path, 'T2'))\n",
        "    os.system(cmd)\n",
        "    cmd = \"cp %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'N4-GAD'), os.path.join (subj_path, 'GAD'))\n",
        "    os.system(cmd) \n",
        "\n",
        "#!ls -l ./nii/S1        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2GKn6tTy91n"
      },
      "source": [
        "# Cell #3\n",
        "\n",
        "# This unzips known good files processed as above.\n",
        "# skip this cell if you want to use your version\n",
        "\n",
        "for subj in ['S1-4', 'S5-8', 'S9-12', 'S13-16']:\n",
        "    cmd = 'cd ./nii; unzip -q ../%s.zip .' % (subj)\n",
        "    os.system(cmd)\n",
        "# must also delete the DICOM and intermediate files to have enough space to make the new files\n",
        "!rm -rf nii/Reg*\n",
        "!rm -rf nii/N4-*\n",
        "!rm -rf ./images\n",
        "\n",
        "\n",
        "\n",
        "# At this point, we have nifti files (T1.nii.gz, T2.nii.gz, GAD.nii.gz) for each subject\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emAoMBNF8yPH"
      },
      "source": [
        "# Cell #4\n",
        "\n",
        "# There is also a text file called 'TumorSlices.csv' that I created which has subject ID, \n",
        "# first slice with contrast enhancement and last slice with contrast enhancement.\n",
        "# note that subjects 2 and 14 don't have much enhancement\n",
        "# we will read this into a Pandas dataframe\n",
        "# Pandas is very popular for data analysis, and has a built-in function to read CSV (and excel) files\n",
        "import pandas as pd\n",
        "\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1fFSTDx8kEhVbXXd9IrQYgIeX8HknaOle' -O ./TumorSlices.csv\n",
        "df = pd.read_csv ('./TumorSlices.csv')\n",
        "print (df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prfwTHAoUSxp"
      },
      "source": [
        "# Cell #5\n",
        "# create new versions of the T1, GAD, and T2 images that range from 0 to 255, and where the 0 intensity value maps to the 5th percentile value \n",
        "# and 255 maps to the 95th percentile value.\n",
        "import imageio\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "MIN_MR = 20\n",
        "\n",
        "def rescale_5_95_percentile(image):\n",
        "    dims = np.shape(image)\n",
        "    image_1d = image.reshape(1, image.size)\n",
        "    above = np.where(image_1d>MIN_MR, image_1d, image_1d)\n",
        "    if above.size < image_1d.size/2:\n",
        "        above = image_1d # avoid bad MIN_MR thresholds\n",
        "    sorted_im = np.sort(above, axis = None)\n",
        "    \n",
        "    start = int(sorted_im.size / 20)  # 20 = 5%\n",
        "    end = int(sorted_im.size * 19 / 20) # 95%\n",
        "    start_val = sorted_im[start]\n",
        "    end_val = sorted_im[end]\n",
        "    \n",
        "    image = np.maximum(image, start_val) # map values below the start_val to start_val\n",
        "    image = np.minimum(image, end_val)   # map values above the end_val to end_val\n",
        "    image = image - start_val # subtract the starting intensity\n",
        "\n",
        " #   print (\"rescaling range \" + str(newmin) + \" to \" + str(histo[1][index]))\n",
        "    image = (np.maximum(image, 0) / image.max()) * 255.0\n",
        "    return image\n",
        "\n",
        "def nifti_to_img(red_file, green_file, blue_file, not_dir, yes_dir, startSlice, endSlice, subject):\n",
        "### red_ green_ and blue_files are the nifit files that will be combined to go into the PNG\n",
        "### not_dir is the direcotry where PNGs are stored if they are not in the (inclusive)\n",
        "### range set by startSlice/endSlice\n",
        "### yes_dir is where they are stored when they ARE in the range\n",
        "### subject is the ID so that we can track where images came from\n",
        "\n",
        "    try:\n",
        "        nifti = nib.load(red_file)\n",
        "        nif_header = nifti.header\n",
        "        red_image = nifti.get_fdata()\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "    try:\n",
        "        if os.path.isfile(green_file):\n",
        "            nifti = nib.load(green_file)\n",
        "            nif_header = nifti.header\n",
        "            green_image = nifti.get_fdata()\n",
        "        else:\n",
        "            pass\n",
        "    except:  # if can't load, then use red image\n",
        "        green_image = red_image\n",
        "    \n",
        "    try:\n",
        "        if os.path.isfile(blue_file):\n",
        "            nifti = nib.load(blue_file)\n",
        "\n",
        "            nif_header = nifti.header\n",
        "            blue_image = nifti.get_fdata()\n",
        "        else:\n",
        "            pass\n",
        "    except:  # if can't load, then use red image\n",
        "        blue_image = red_image\n",
        "        \n",
        "# now scale the intensity for each image        \n",
        "    red_image = rescale_5_95_percentile(red_image)\n",
        "    green_image = rescale_5_95_percentile(green_image)\n",
        "    blue_image = rescale_5_95_percentile(blue_image)\n",
        "# then convert to 8 bits\n",
        "    red_image = red_image.astype(np.uint8)     \n",
        "    green_image = green_image.astype(np.uint8)     \n",
        "    blue_image = blue_image.astype(np.uint8)   \n",
        "    \n",
        "# get the number of slices\n",
        "    dims = np.shape(red_image)\n",
        "    zd = dims[2]\n",
        "\n",
        "    for z in range(0, zd):\n",
        "        outname = subject + \"-{0:04d}\".format(z) + '.png'\n",
        "        if z >= startSlice and z <= endSlice:  # this is enhancing\n",
        "            out_dir = yes_dir\n",
        "        else:\n",
        "            out_dir = not_dir\n",
        "        outname = os.path.join(out_dir, outname)\n",
        "        if not os.path.exists(out_dir):\n",
        "            os.makedirs(out_dir)\n",
        "        combined = np.dstack((red_image[:,:,z],green_image[:,:,z],\n",
        "                              blue_image[:,:,z]))\n",
        "## . images come in rotated\n",
        "        combined = np.rot90(combined, k=1)\n",
        "#        print ('Name: ' + outname)\n",
        "        imageio.imwrite(outname, combined)\n",
        "    return zd\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EuA77JqUbfB"
      },
      "source": [
        "# Cell #6\n",
        "# take the GAD nii, scale it to 0-255 and store that into the red channel\n",
        "# same for T1 (green) and T2 (blue)\n",
        "# PNG files are stored in enh / nonenh folders based on the csv file\n",
        "\n",
        "# store the png files into enhancing or nonenhancing folders after making sure they are cleared\n",
        "\n",
        "!rm -rf classified\n",
        "\n",
        "!mkdir classified\n",
        "\n",
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    red_f = os.path.join(subj_path, 'GAD.nii.gz')\n",
        "    green_f = os.path.join(subj_path, 'T1.nii.gz')\n",
        "    blue_f = os.path.join(subj_path, 'T2.nii.gz')\n",
        "    startSlice = df.loc[df.Subject == subj, 'StartSlice'].values[0]\n",
        "    endSlice = df.loc[df.Subject == subj, 'EndSlice'].values[0]\n",
        "    print (\"Making PNG file for \" + subj + \" start: \" + str(startSlice) + \" end: \" + str(endSlice))\n",
        "    count = nifti_to_img(red_f, green_f, blue_f, './classified/not', './classified/enh', startSlice, endSlice, subj)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MeAVs12qLNX"
      },
      "source": [
        "# Cell #7\n",
        "# now we are ready to load data and train classifier\n",
        "# while we did this in separate cells before, we will do it all in one\n",
        "# this should look familiar.\n",
        "!pip3 install fastai\n",
        "from fastai.vision import *\n",
        "\n",
        "classes_dir = \"./classified\"\n",
        "\n",
        "np.random.seed(42)\n",
        "data = ImageDataBunch.from_folder(classes_dir, train=\".\", valid_pct=0.2,\n",
        "        ds_tfms=get_transforms(), size=64, num_workers=4).normalize(imagenet_stats)\n",
        "data.classes\n",
        "data.classes, data.c, len(data.train_ds), len(data.valid_ds)\n",
        "\n",
        "learn = cnn_learner(data, models.resnet34, metrics=error_rate)\n",
        "\n",
        "learn.fit_one_cycle(50)\n",
        "\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()\n",
        "# not great performance. \n",
        "# look at some errors--why is it failing? \n",
        "interp.plot_top_losses(9, figsize=(10,10))\n",
        "doc(interp.plot_top_losses)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}